{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: This reads the marriage patterns for the non-reform states in the 1970\n",
    "  wave of the Choo and Siow *JPE* 2006 data.\n",
    "output-file: read_data.html\n",
    "title: read_data\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import operator\n",
    "from fastcore.test import *\n",
    "from sys import platform\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "from cupid_matching.matching_utils import Matching, _compute_margins, _get_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_root_dir(\n",
    "                    # no argument\n",
    "    ) -> Path:      # the package directory\n",
    "    \"\"\" returns the package directory \"\"\"\n",
    "    root_dir = Path.cwd().parent\n",
    "#     if platform in [\"linux\", \"linux2\"]:        # we are deploying\n",
    "#         root_dir = Path.cwd().parent\n",
    "    return root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def read_margins(\n",
    "    data_dir: Path      # the data directory\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]: \n",
    "    \"\"\"reads and returns the margins for men and for women \"\"\"\n",
    "    nx = np.loadtxt(data_dir / \"nx70n.txt\")\n",
    "    my = np.loadtxt(data_dir / \"my70n.txt\")\n",
    "    return nx, my\n",
    "\n",
    "def read_marriages(\n",
    "    data_dir: Path      # the data directory\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]: \n",
    "    \"\"\" reads and returns the marriages and the variances\"\"\"\n",
    "    muxy = np.loadtxt(data_dir / \"muxy70nN.txt\")\n",
    "    varmus = np.loadtxt(data_dir / \"varmus70nN.txt\")\n",
    "    return muxy, varmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def reshape_varcov(\n",
    "    varmus: np.ndarray,      #  muxy row major, then  mux0, then mu0y packed in both dimensions\n",
    "    mus: Matching,           #  the original Matching\n",
    "    n_households: int        #  the number of households we want\n",
    ") -> tuple[np.ndarray]:      #  the 6 constituent blocks of the normalized variance-covariance\n",
    "    \"\"\" splits the variance-covariance matrix \n",
    "    and renomalizes for a requested total number of households\n",
    "    \"\"\"\n",
    "    muxy, mux0, mu0y, *_ = mus.unpack()\n",
    "    ncat_men, ncat_women = muxy.shape\n",
    "    n_prod_categories = ncat_men * ncat_women\n",
    "    # first we reshape\n",
    "    varmus_xyzt = varmus[:n_prod_categories, :n_prod_categories]\n",
    "    varmus_xyz0 = varmus[:n_prod_categories,\n",
    "                                n_prod_categories:(n_prod_categories + ncat_men)]\n",
    "    varmus_xy0t = varmus[:n_prod_categories,\n",
    "                                (n_prod_categories + ncat_men):]\n",
    "    varmus_x0z0 = varmus[n_prod_categories:(n_prod_categories + ncat_men),\n",
    "                                n_prod_categories:(n_prod_categories + ncat_men)]\n",
    "    varmus_x00y = varmus[n_prod_categories:(n_prod_categories + ncat_men), \n",
    "                         (n_prod_categories + ncat_men):]\n",
    "    varmus_0y0t = varmus[(n_prod_categories + ncat_men):, \n",
    "                         (n_prod_categories + ncat_men):]\n",
    "    varcovs = (varmus_xyzt, varmus_xyz0, varmus_xy0t,\n",
    "              varmus_x0z0, varmus_x00y, varmus_0y0t)\n",
    "    # then we rescale\n",
    "    n_households_mus = np.sum(muxy) + np.sum(mux0) + np.sum(mu0y)\n",
    "    rescale_factor = n_households/n_households_mus\n",
    "    rescale_factor2 =  rescale_factor*rescale_factor\n",
    "    varcovs = tuple(v*rescale_factor2 for v in varcovs)\n",
    "    return varcovs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "muxy = np.array([[0, 2], [1,3], [4,5]])\n",
    "nx = np.array([3, 5, 10])\n",
    "my = np.array([7, 14])\n",
    "n_types_men = nx.size\n",
    "n_types_women = my.size\n",
    "n_prod_categories = n_types_men*n_types_women\n",
    "mus = Matching(muxy, nx, my)\n",
    "mux0, mu0y = _get_singles(muxy, nx, my)\n",
    "n_households = np.sum(muxy) + np.sum(mux0) + np.sum(mu0y)\n",
    "new_nh = 331\n",
    "varmus = np.random.uniform(size=(11, 11))\n",
    "varcovs_rescaled = reshape_varcov(varmus, mus, new_nh)\n",
    "varcovs_xyzt, varcovs_xyz0, varcovs_xy0t, \\\n",
    "              varcovs_x0z0, varcovs_x00y, varcovs_0y0t = varcovs_rescaled\n",
    "i, j, k, l = (2, 1, 1, 1)\n",
    "test_close(varcovs_xyzt[i*n_types_women+j,k*n_types_women+l], \n",
    "           varmus[i*n_types_women+j,k*n_types_women+l]*((new_nh/n_households)**2))\n",
    "test_close(varcovs_x00y[i, j], \n",
    "           varmus[n_prod_categories+i, n_prod_categories+n_types_men+j]*((new_nh/n_households)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def rescale_mus(\n",
    "    mus: Matching,         # muxy, mux0, mu0y\n",
    "    n_households: int | float    # the number of households we want\n",
    ") -> Matching:  # the normalized Matching after rescaling\n",
    "    \"\"\" normalizes the marriages and margins to a requested total number of households\"\"\"\n",
    "    muxy, mux0, mu0y, nx, my = mus.unpack()\n",
    "    n_households_mus = np.sum(muxy) + np.sum(mux0) + np.sum(mu0y)\n",
    "    rescale_factor = n_households/n_households_mus\n",
    "    muxy_norm = muxy * rescale_factor\n",
    "    nx_norm = nx * rescale_factor\n",
    "    my_norm = my  * rescale_factor\n",
    "    mus_norm = Matching(muxy_norm, nx_norm, my_norm)\n",
    "    return mus_norm\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "muxy = np.array([[0, 2], [1,3], [4,5]])\n",
    "nx = np.array([3, 5, 10])\n",
    "my = np.array([7, 14])\n",
    "mus = Matching(muxy, nx, my)\n",
    "mux0, mu0y = _get_singles(muxy, nx, my)\n",
    "n_households = np.sum(muxy) + np.sum(mux0) + np.sum(mu0y)\n",
    "new_nh = 331\n",
    "mus_rescaled = rescale_mus(mus, new_nh)\n",
    "muxy_rescaled, mux0_rescaled, mu0y_rescaled, nx_rescaled, my_rescaled = mus_rescaled.unpack()\n",
    "test_close(muxy_rescaled[2, 1], muxy[2,1]*new_nh/n_households)\n",
    "test_close(nx_rescaled[1], nx[1]*new_nh/n_households)\n",
    "test_close(mu0y_rescaled[1], mu0y[1]*new_nh/n_households)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "def _get_zeros_mu(\n",
    "    mu: np.ndarray,\n",
    "    eps: float=1e-9\n",
    ") -> Tuple[bool, np.ndarray, float]:\n",
    "    mu_size = mu.size\n",
    "    nonzero_mu = mu[mu > eps]\n",
    "    min_nonzero = np.min(nonzero_mu)\n",
    "    n_zeros_mu = mu_size - nonzero_mu.size\n",
    "    mu_has_zeros = (n_zeros_mu > 0)\n",
    "    return mu_has_zeros, mu_size, min_nonzero\n",
    "    \n",
    "    \n",
    "def remove_zero_cells(\n",
    "    mus: Matching,         # muxy, mux0, mu0y, n, m\n",
    "    coeff: int = 100 # default scale factor for delta\n",
    ") -> Matching:  # the transformed muxy, mux0, mu0y, nx, my\n",
    "    \"\"\"add small number `delta` to 0-cells to avoid numerical issues\"\"\"\n",
    "    muxy, mux0, mu0y, *_ = mus.unpack()\n",
    "    zeros_muxy, muxy_size, min_muxy = _get_zeros_mu(muxy)\n",
    "    zeros_mux0, mux0_size, min_mux0 = _get_zeros_mu(mux0)\n",
    "    zeros_mu0y, mu0y_size, min_mu0y = _get_zeros_mu(mu0y)\n",
    "    some_zeros = (zeros_muxy or zeros_mux0 or zeros_mu0y)\n",
    "    if not some_zeros:\n",
    "        return mus\n",
    "    else:\n",
    "        delta = min(min_muxy, min_mux0, min_mu0y)/coeff\n",
    "        muxy_fixed = muxy.astype(float)\n",
    "        mux0_fixed = mux0.astype(float)\n",
    "        mu0y_fixed = mu0y.astype(float)\n",
    "        n_cells = 0\n",
    "        if zeros_muxy:\n",
    "            muxy_fixed += delta\n",
    "            n_cells += muxy_size\n",
    "        if zeros_mux0:\n",
    "            mux0_fixed += delta\n",
    "            n_cells += mux0_size\n",
    "        if zeros_mu0y:\n",
    "            mu0y_fixed += delta\n",
    "            n_cells += mu0y_size\n",
    "        n_households = np.sum(muxy)+np.sum(mux0)+np.sum(mu0y)\n",
    "        scale_factor = n_households/(n_households+delta*n_cells)\n",
    "        muxy_fixed *= scale_factor\n",
    "        mux0_fixed *= scale_factor\n",
    "        mux0_fixed *= scale_factor\n",
    "        nx_fixed, my_fixed = _compute_margins(muxy_fixed, mux0_fixed, mu0y_fixed)\n",
    "        mus_fixed = Matching(muxy_fixed, nx_fixed, my_fixed)\n",
    "        return mus_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "muxy = np.array([[0, 2], [1,3], [4,5]])\n",
    "nx = np.array([3, 5, 10])\n",
    "my = np.array([7, 14])\n",
    "mus = Matching(muxy, nx, my)\n",
    "mux0, mu0y = _get_singles(muxy, nx, my)\n",
    "changed_mus = remove_zero_cells(mus)\n",
    "changed_muxy, changed_mux0, changed_mu0y, changed_nx, changed_my = changed_mus.unpack()\n",
    "for changed_mu, old_mu in zip([changed_muxy, changed_mux0, changed_mu0y, changed_nx, changed_my],\n",
    "                       [muxy, mux0, mu0y, nx, my]):\n",
    "    diff_mu = np.abs(changed_mu - old_mu)\n",
    "    test(np.max(diff_mu), 0.1, operator.lt)\n",
    "    test(np.min(changed_mu), 0.0, operator.gt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
